{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfRH+23bc9MEF+rtPb7/dB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/homichal3/Recognizing-basketball-offensive-moves/blob/main/last_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTKUsc7Bh1UL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sqrt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eaoo_J2Lh4Sv",
        "outputId": "e97573db-1cdc-4f92-e546-f5d50d5fe67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn import svm\n",
        "from sklearn import tree \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,plot_confusion_matrix "
      ],
      "metadata": {
        "id": "vNuwbP3WjKxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import smtplib\n",
        "import imghdr\n",
        "from email.message import EmailMessage"
      ],
      "metadata": {
        "id": "ojUXpy-ygQjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def acceleration_magnitude(df1):\n",
        "  i = 1\n",
        "  new1 = []\n",
        "  for i in range(len(df1.values[:,2])):\n",
        "    new1.append(sqrt(df1.values[i,2]**2 + df1.values[i,3]**2 + df1.values[i,4]**2))\n",
        "  return new1"
      ],
      "metadata": {
        "id": "PbpaO1D9h5IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def biggest_value_mag(df, width):\n",
        "  mx = max(df)\n",
        "  for i in range(len(df)):\n",
        "    if mx == df[i]:\n",
        "      index1 = i\n",
        "    if mx < abs(df[i]):\n",
        "      mx = abs(df[i])\n",
        "      index1 = i\n",
        "  index2 = index1+int((width/2))\n",
        "  index1 -= int((width/2))\n",
        "  return index1, index2"
      ],
      "metadata": {
        "id": "IWANEu1_h9KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aritmetic_mean(val):\n",
        "  return sum(val)/len(val)"
      ],
      "metadata": {
        "id": "Jo62PoFCiAPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def signal_energy(val):\n",
        "  val = np.reshape(val,(-1, len(val)))\n",
        "  p = np.sum(val*val,1)/val.size\n",
        "  e = p*val.size\n",
        "  return e"
      ],
      "metadata": {
        "id": "9WLpQrQZiBfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_values_from_movement(mag, list1, signal_ene, mean, labels, label, width):\n",
        "  index = 0;\n",
        "  count = 0\n",
        "  for i in range(len(mag)):\n",
        "    if i % width == 0 and i > 0:\n",
        "      list1.append(mag[index:i])\n",
        "      signal_ene.append(signal_energy(mag[index:i]))\n",
        "      mean.append(aritmetic_mean(mag[index:i]))\n",
        "      index = i\n",
        "      labels.append(label)\n",
        "      count+=1\n",
        "    elif count == 20:\n",
        "      break\n",
        "  return list1, signal_ene, mean, labels"
      ],
      "metadata": {
        "id": "MzvE9EysiDZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_values_for_shotting(mag, list1, signal_ene, mean, labels, label, width):\n",
        "  i, j = biggest_value_mag(mag,width)\n",
        "  list1.append(mag[i:j])\n",
        "  signal_ene.append(signal_energy(mag[i:j]))\n",
        "  mean.append(aritmetic_mean(mag[i:j]))\n",
        "  labels.append(label)\n",
        "  return list1, signal_ene, mean, labels"
      ],
      "metadata": {
        "id": "UX-ToqoCiEly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_augmentation_rev(mag, list1, signal_ene, mean, labels, label, width):\n",
        "  i, j = biggest_value_mag(mag, width)\n",
        "  new_mag = mag[i:j]\n",
        "  new_mag = new_mag[::-1]\n",
        "  list1.append(new_mag)\n",
        "  signal_ene.append(signal_energy(new_mag))\n",
        "  mean.append(aritmetic_mean(new_mag))\n",
        "  labels.append(label)\n",
        "  return list1, signal_ene, mean, labels"
      ],
      "metadata": {
        "id": "aa1JCg00iP5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_augmentation_warp(mag, list1, signal_ene, mean, labels, label, value, width):\n",
        "  i, j = biggest_value_mag(mag, width)\n",
        "  list1.append(mag[i-value:j-value])\n",
        "  signal_ene.append(signal_energy(mag[i-value:j-value]))\n",
        "  mean.append(aritmetic_mean(mag[i-value:j-value]))\n",
        "  labels.append(label)\n",
        "  list1.append(mag[i+value:j+value])\n",
        "  signal_ene.append(signal_energy(mag[i+value:j+value]))\n",
        "  mean.append(aritmetic_mean(mag[i+value:j+value]))\n",
        "  labels.append(label)\n",
        "  return list1, signal_ene, mean, labels"
      ],
      "metadata": {
        "id": "dOeu_tlUiSvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_augmentation_up_down(mag, list1, signal_ene, mean, labels, label, value, width):\n",
        "  i, j = biggest_value_mag(mag, width)\n",
        "  temp = mag[i:j]\n",
        "  temp_incremented = [x+value for x in temp]\n",
        "  temp_decremented = [x-value for x in temp]\n",
        "\n",
        "  list1.append(temp_incremented)\n",
        "  signal_ene.append(signal_energy(temp_incremented))\n",
        "  mean.append(aritmetic_mean(temp_incremented))\n",
        "  labels.append(label)\n",
        "\n",
        "  list1.append(temp_decremented)\n",
        "  signal_ene.append(signal_energy(temp_decremented))\n",
        "  mean.append(aritmetic_mean(temp_decremented))\n",
        "  labels.append(label)\n",
        "  return list1, signal_ene, mean, labels"
      ],
      "metadata": {
        "id": "DMC-hIU_KFOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_augmentation_scaling(mag, list1, signal_ene, mean, labels, label, value, width):\n",
        "  i, j = biggest_value_mag(mag, width)\n",
        "  temp = mag[i:j]\n",
        "  temp_incremented = [x*value for x in temp]\n",
        "\n",
        "\n",
        "  list1.append(temp_incremented)\n",
        "  signal_ene.append(signal_energy(temp_incremented))\n",
        "  mean.append(aritmetic_mean(temp_incremented))\n",
        "  labels.append(label)\n",
        "\n",
        "  return list1, signal_ene, mean, labels"
      ],
      "metadata": {
        "id": "3lNSIjSnxBEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_values_from_movement_gyr(mag, list1, signal_ene, mean, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels, label, width):\n",
        "  index = 0;\n",
        "  count = 0\n",
        "  for i in range(len(mag)):\n",
        "    if i % width == 0 and i > 0:\n",
        "\n",
        "      temp = mag[index:i]\n",
        "      z = df_gyr.values[index:i,2]\n",
        "      y = df_gyr.values[index:i,3]\n",
        "      x = df_gyr.values[index:i,4]\n",
        "      temp.extend(z)\n",
        "      temp.extend(y)\n",
        "      temp.extend(x)    \n",
        "\n",
        "      z_mean_gyr.append(aritmetic_mean(z))\n",
        "      y_mean_gyr.append(aritmetic_mean(y))\n",
        "      x_mean_gyr.append(aritmetic_mean(x))\n",
        "\n",
        "      list1.append(temp)\n",
        "      signal_ene.append(signal_energy(mag[index:i]))\n",
        "      mean.append(aritmetic_mean(mag[index:i]))\n",
        "\n",
        "      index = i\n",
        "      labels.append(label)\n",
        "      count+=1\n",
        "    elif count == 30:\n",
        "      break\n",
        "  return list1, signal_ene, mean, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels"
      ],
      "metadata": {
        "id": "6jW62lHiqb9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_values_for_shotting_gyr(mag, list1, signal_ene,  mean, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels, label, width):\n",
        "  i, j = biggest_value_mag(mag, width)\n",
        "\n",
        "  temp = mag[i:j]\n",
        "  z = df_gyr.values[i:j,2]\n",
        "  y = df_gyr.values[i:j,3]\n",
        "  x = df_gyr.values[i:j,4]\n",
        "  temp.extend(z)\n",
        "  temp.extend(y)\n",
        "  temp.extend(x)\n",
        "\n",
        "  z_mean_gyr.append(aritmetic_mean(df_gyr.values[i:j,2]))\n",
        "  y_mean_gyr.append(aritmetic_mean(df_gyr.values[i:j,3]))\n",
        "  x_mean_gyr.append(aritmetic_mean(df_gyr.values[i:j,4]))\n",
        "\n",
        "  list1.append(temp)\n",
        "  signal_ene.append(signal_energy(mag[i:j]))\n",
        "  mean.append(aritmetic_mean(mag[i:j]))\n",
        "  labels.append(label)\n",
        "  \n",
        "  return list1, signal_ene, mean, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels"
      ],
      "metadata": {
        "id": "pEyK9ikCqXFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_augmentation_rev_gyr(mag, list1, signal_ene, mean, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels, label, width):\n",
        "  i, j = biggest_value_mag(mag, width)\n",
        "  new_mag = mag[i:j]\n",
        "  new_mag = new_mag[::-1]\n",
        "  signal_ene.append(signal_energy(new_mag))\n",
        "  mean.append(aritmetic_mean(new_mag))\n",
        "\n",
        "  new_gyr_z = df_gyr.values[i:j,2]\n",
        "  new_gyr_z = new_gyr_z[::-1]\n",
        "  new_gyr_y = df_gyr.values[i:j,3]\n",
        "  new_gyr_y = new_gyr_y[::-1]\n",
        "  new_gyr_x = df_gyr.values[i:j,4]\n",
        "  new_gyr_x = new_gyr_x[::-1]\n",
        "\n",
        "\n",
        "  temp = new_mag\n",
        "  temp.extend(new_gyr_z)\n",
        "  temp.extend(new_gyr_y)\n",
        "  temp.extend(new_gyr_x)\n",
        "\n",
        "  z_mean_gyr.append(aritmetic_mean(new_gyr_z))\n",
        "  y_mean_gyr.append(aritmetic_mean(new_gyr_y))\n",
        "  x_mean_gyr.append(aritmetic_mean(new_gyr_x))\n",
        "\n",
        "  list1.append(temp)\n",
        "  labels.append(label)\n",
        "\n",
        "  return list1, signal_ene, mean, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels"
      ],
      "metadata": {
        "id": "wQZaxOpTqRbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_augmentation_warp_gyr(mag, list1, signal_ene, mean, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels, label, value, width):\n",
        "  i, j = biggest_value_mag(mag, width)\n",
        "\n",
        "  temp = mag[i-value:j-value]\n",
        "  z = df_gyr.values[i-value:j-value,2]\n",
        "  y = df_gyr.values[i-value:j-value,3]\n",
        "  x = df_gyr.values[i-value:j-value,4]\n",
        "  temp.extend(z)\n",
        "  temp.extend(y)\n",
        "  temp.extend(x)\n",
        "\n",
        "  z_mean_gyr.append(aritmetic_mean(df_gyr.values[i-value:j-value,2]))\n",
        "  y_mean_gyr.append(aritmetic_mean(df_gyr.values[i-value:j-value,3]))\n",
        "  x_mean_gyr.append(aritmetic_mean(df_gyr.values[i-value:j-value,4]))\n",
        "\n",
        "\n",
        "  list1.append(temp)\n",
        "  signal_ene.append(signal_energy(mag[i-value:j-value]))\n",
        "  mean.append(aritmetic_mean(mag[i-value:j-value]))\n",
        "  labels.append(label)\n",
        "\n",
        "  temp = mag[i+value:j+value]\n",
        "  z = df_gyr.values[i+value:j+value,2]\n",
        "  y = df_gyr.values[i+value:j+value,3]\n",
        "  x = df_gyr.values[i+value:j+value,4]\n",
        "  temp.extend(z)\n",
        "  temp.extend(y)\n",
        "  temp.extend(x)\n",
        "\n",
        "  z_mean_gyr.append(aritmetic_mean(df_gyr.values[i+value:j+value,2]))\n",
        "  y_mean_gyr.append(aritmetic_mean(df_gyr.values[i+value:j+value,3]))\n",
        "  x_mean_gyr.append(aritmetic_mean(df_gyr.values[i+value:j+value,4]))\n",
        "\n",
        "  \n",
        "  list1.append(temp)\n",
        "  signal_ene.append(signal_energy(mag[i+value:j+value]))\n",
        "  mean.append(aritmetic_mean(mag[i+value:j+value]))\n",
        "  labels.append(label)\n",
        "\n",
        "  return list1, signal_ene,  mean, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels"
      ],
      "metadata": {
        "id": "qH3mkQe9qNoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_augmentation_scaling_gyr(mag, list1, signal_ene, mean, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels, label, value, width):\n",
        "  i, j = biggest_value_mag(mag,width)\n",
        "  temp = mag[i:j]\n",
        "  temp_scaled = [x*value for x in temp]\n",
        "\n",
        "  signal_ene.append(signal_energy(temp_scaled))\n",
        "  mean.append(aritmetic_mean(temp_scaled))\n",
        "\n",
        "  z = df_gyr.values[i:j,2]\n",
        "  y = df_gyr.values[i:j,3]\n",
        "  x = df_gyr.values[i:j,4]\n",
        "  temp_scaled.extend(z)\n",
        "  temp_scaled.extend(y)\n",
        "  temp_scaled.extend(x)\n",
        "\n",
        "  z_mean_gyr.append(aritmetic_mean(z))\n",
        "  y_mean_gyr.append(aritmetic_mean(y))\n",
        "  x_mean_gyr.append(aritmetic_mean(x))\n",
        "\n",
        "  list1.append(temp_scaled)\n",
        "  labels.append(label)\n",
        "\n",
        "  return list1, signal_ene, mean, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels"
      ],
      "metadata": {
        "id": "Kam3bl-Z_Yow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_augmentation_up_down_gyr(mag, list1, signal_ene, mean, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels, label, value, width):\n",
        "  i, j = biggest_value_mag(mag,width)\n",
        "  temp = mag[i:j]\n",
        "  temp_incremented = [x+value for x in temp]\n",
        "  temp_decremented = [x-value for x in temp]\n",
        "\n",
        "  signal_ene.append(signal_energy(temp_incremented))\n",
        "  mean.append(aritmetic_mean(temp_incremented))\n",
        "\n",
        "  z = df_gyr.values[i:j,2]\n",
        "  y = df_gyr.values[i:j,3]\n",
        "  x = df_gyr.values[i:j,4]\n",
        "  temp_incremented.extend(z)\n",
        "  temp_incremented.extend(y)\n",
        "  temp_incremented.extend(x)\n",
        "\n",
        "  z_mean_gyr.append(aritmetic_mean(z))\n",
        "  y_mean_gyr.append(aritmetic_mean(y))\n",
        "  x_mean_gyr.append(aritmetic_mean(x))\n",
        "\n",
        "  list1.append(temp_incremented)\n",
        "  labels.append(label)\n",
        "\n",
        "\n",
        "\n",
        "  signal_ene.append(signal_energy(temp_decremented))\n",
        "  mean.append(aritmetic_mean(temp_decremented))\n",
        "\n",
        "  z = df_gyr.values[i:j,2]\n",
        "  y = df_gyr.values[i:j,3]\n",
        "  x = df_gyr.values[i:j,4]\n",
        "  temp_decremented.extend(z)\n",
        "  temp_decremented.extend(y)\n",
        "  temp_decremented.extend(x)\n",
        "\n",
        "  z_mean_gyr.append(aritmetic_mean(z))\n",
        "  y_mean_gyr.append(aritmetic_mean(y))\n",
        "  x_mean_gyr.append(aritmetic_mean(x))\n",
        "\n",
        "  list1.append(temp_decremented)\n",
        "  labels.append(label)\n",
        "  return list1, signal_ene, mean, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels"
      ],
      "metadata": {
        "id": "c5ICfDD9Ryow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_indexes(mag, labels, width):\n",
        "  temp_mag = mag\n",
        "  zeros = np.zeros(width)\n",
        "  indexes = []\n",
        "  iter = len(labels)\n",
        "  width = int((width)/2)\n",
        "\n",
        "  while iter != 0:\n",
        "    mx = max(temp_mag)\n",
        "    for i in range(len(temp_mag)):\n",
        "      if(mx == mag[i]):\n",
        "        indexes.append(i)\n",
        "        temp_mag[i-width:i+width] = zeros\n",
        "        iter -= 1\n",
        "        break\n",
        "  return indexes"
      ],
      "metadata": {
        "id": "ToP9mqUqLD5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_labels(labels, indexes):\n",
        "  j = 0\n",
        "  iter = len(labels)\n",
        "  new_label = np.zeros(len(labels))\n",
        "  while iter != 0:\n",
        "    mini = min(indexes)\n",
        "    for i in range(len(indexes)):\n",
        "      if mini == indexes[i]:\n",
        "        new_label[i] = labels[j]\n",
        "        j += 1\n",
        "        indexes[i] = 100000000000\n",
        "        iter -= 1\n",
        "  zeros = np.zeros(int(len(labels)/2))\n",
        "  ones = np.ones(int(len(labels)/2))\n",
        "  new_label = np.concatenate((new_label, zeros, ones))\n",
        "  return new_label"
      ],
      "metadata": {
        "id": "M2qS05LJLFy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cutting_chart_to_pieces(mag, list1, mean, signal_ene, labels, labels_new, width):\n",
        "  iter = len(labels_new)\n",
        "  width = int((width)/2)\n",
        "  while iter != 0:\n",
        "    mx = max(mag)\n",
        "    if iter > int(len(labels_new)/4):\n",
        "      for i in range(len(mag)):\n",
        "        if mx == mag[i]:\n",
        "          list1.append(mag[i-width:i+width])\n",
        "          mean.append(aritmetic_mean(mag[i-width:i+width]))\n",
        "          signal_ene.append(signal_energy(mag[i-width:i+width]))\n",
        "          del mag[i-width:i+width]\n",
        "          iter -= 1\n",
        "          break\n",
        "    elif iter <= int(len(labels_new)/4):\n",
        "      for i in range(len(mag)):\n",
        "        mn = min(mag)\n",
        "        if mn == mag[i]:\n",
        "          list1.append(mag[i-width:i+width])\n",
        "          mean.append(aritmetic_mean(mag[i-width:i+width]))\n",
        "          signal_ene.append(signal_energy(mag[i-width:i+width]))\n",
        "          del mag[i-width:i+width]\n",
        "          iter -= 1\n",
        "          break\n",
        "\n",
        "  labels = np.concatenate((labels,labels_new))\n",
        "  return list1, mean, signal_ene, labels "
      ],
      "metadata": {
        "id": "uUAh_5nXLX2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cutting_chart_to_pieces_gyr(mag, list1, mean, signal_ene, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels, labels_new, width):\n",
        "  iter = len(labels_new)\n",
        "  z = df_gyr.values[:,2]\n",
        "  y = df_gyr.values[:,3]\n",
        "  x = df_gyr.values[:,4]\n",
        "  z = z.tolist()\n",
        "  y = y.tolist()\n",
        "  x = x.tolist()\n",
        "\n",
        "  width = int((width)/2)\n",
        "\n",
        "  while iter != 0 :\n",
        "    if iter > int(len(labels_new)/4):\n",
        "      mx = max(mag)\n",
        "      for i in range(len(mag)):\n",
        "        if mx == mag[i] :\n",
        "          mean.append(aritmetic_mean(mag[i-width:i+width]))\n",
        "          signal_ene.append(signal_energy(mag[i-width:i+width]))\n",
        "\n",
        "          temp = mag[i-width:i+width]\n",
        "\n",
        "          temp.extend(z[i-width:i+width])\n",
        "          temp.extend(y[i-width:i+width])\n",
        "          temp.extend(x[i-width:i+width])    \n",
        "\n",
        "\n",
        "          z_mean_gyr.append(aritmetic_mean(z[i-width:i+width]))\n",
        "          y_mean_gyr.append(aritmetic_mean(y[i-width:i+width]))\n",
        "          x_mean_gyr.append(aritmetic_mean(x[i-width:i+width]))\n",
        "\n",
        "          list1.append(temp)\n",
        "\n",
        "\n",
        "          del z[i-width:i+width]\n",
        "          del y[i-width:i+width]\n",
        "          del x[i-width:i+width]\n",
        "          del mag[i-width:i+width]\n",
        "          iter -= 1\n",
        "          break\n",
        "\n",
        "\n",
        "    elif iter <= int(len(labels_new)/4):\n",
        "      for i in range(len(mag)):\n",
        "        mn = min(mag)\n",
        "        if mn == mag[i]:\n",
        "\n",
        "          mean.append(aritmetic_mean(mag[i-width:i+width]))\n",
        "          signal_ene.append(signal_energy(mag[i-width:i+width]))\n",
        "\n",
        "          temp = mag[i-width:i+width]\n",
        "          temp.extend(z[i-width:i+width])\n",
        "          temp.extend(y[i-width:i+width])\n",
        "          temp.extend(x[i-width:i+width])    \n",
        "\n",
        "          z_mean_gyr.append(aritmetic_mean(z[i-width:i+width]))\n",
        "          y_mean_gyr.append(aritmetic_mean(y[i-width:i+width]))\n",
        "          x_mean_gyr.append(aritmetic_mean(x[i-width:i+width]))\n",
        "\n",
        "          list1.append(temp)\n",
        "\n",
        "          del z[i-width:i+width]\n",
        "          del y[i-width:i+width]\n",
        "          del x[i-width:i+width]\n",
        "          del mag[i-width:i+width]\n",
        "          iter -= 1\n",
        "          break\n",
        "\n",
        "  labels = np.concatenate((labels,labels_new))\n",
        "  return list1, mean, signal_ene, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels "
      ],
      "metadata": {
        "id": "8tvKwI3CIkD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Database.zip .\n",
        "!unzip Database.zip"
      ],
      "metadata": {
        "id": "f_P5EtK_qBAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e139e9e-be9d-419d-b580-db926db24156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Database.zip\n",
            "   creating: Database_draft/\n",
            "   creating: Database_draft/R1F/\n",
            "  inflating: Database_draft/R1F/R01F.csv  \n",
            "  inflating: Database_draft/R1F/R02F.csv  \n",
            "  inflating: Database_draft/R1F/R04F.csv  \n",
            "  inflating: Database_draft/R1F/R05F.csv  \n",
            "  inflating: Database_draft/R1F/R06F.csv  \n",
            "  inflating: Database_draft/R1F/R07F.csv  \n",
            "  inflating: Database_draft/R1F/R08F.csv  \n",
            "  inflating: Database_draft/R1F/R03F.csv  \n",
            "  inflating: Database_draft/R1F/R09F.csv  \n",
            "  inflating: Database_draft/R1F/R10F.csv  \n",
            "  inflating: Database_draft/R1F/R11F.csv  \n",
            "  inflating: Database_draft/R1F/R12F.csv  \n",
            "  inflating: Database_draft/R1F/R13F.csv  \n",
            "  inflating: Database_draft/R1F/R14F.csv  \n",
            "  inflating: Database_draft/R1F/R15F.csv  \n",
            "   creating: Database_draft/KOZIOL/\n",
            "  inflating: Database_draft/KOZIOL/koziol.csv  \n",
            "   creating: Database_draft/KOZIOL_TRUCHT_BIEG/\n",
            "  inflating: Database_draft/KOZIOL_TRUCHT_BIEG/koziol_trucht_bieg.csv  \n",
            "   creating: Database_draft/R1T/\n",
            "  inflating: Database_draft/R1T/R01T.csv  \n",
            "  inflating: Database_draft/R1T/R03T.csv  \n",
            "  inflating: Database_draft/R1T/R04T.csv  \n",
            "  inflating: Database_draft/R1T/R05T.csv  \n",
            "  inflating: Database_draft/R1T/R02T.csv  \n",
            "  inflating: Database_draft/R1T/R06T.csv  \n",
            "  inflating: Database_draft/R1T/R07T.csv  \n",
            "  inflating: Database_draft/R1T/R08T.csv  \n",
            "  inflating: Database_draft/R1T/R09T.csv  \n",
            "  inflating: Database_draft/R1T/R10T.csv  \n",
            "  inflating: Database_draft/R1T/R11T.csv  \n",
            "  inflating: Database_draft/R1T/R12T.csv  \n",
            "  inflating: Database_draft/R1T/R13T.csv  \n",
            "  inflating: Database_draft/R1T/R14T.csv  \n",
            "  inflating: Database_draft/R1T/R15T.csv  \n",
            "   creating: Database_draft/R2F/\n",
            "  inflating: Database_draft/R2F/R01F.csv  \n",
            "  inflating: Database_draft/R2F/R02F.csv  \n",
            "  inflating: Database_draft/R2F/R03F.csv  \n",
            "  inflating: Database_draft/R2F/R04F.csv  \n",
            "  inflating: Database_draft/R2F/R05F.csv  \n",
            "  inflating: Database_draft/R2F/R06F.csv  \n",
            "  inflating: Database_draft/R2F/R07F.csv  \n",
            "  inflating: Database_draft/R2F/R08F.csv  \n",
            "  inflating: Database_draft/R2F/R09F.csv  \n",
            "  inflating: Database_draft/R2F/R10F.csv  \n",
            "  inflating: Database_draft/R2F/R11F.csv  \n",
            "  inflating: Database_draft/R2F/R13F.csv  \n",
            "  inflating: Database_draft/R2F/R14F.csv  \n",
            "  inflating: Database_draft/R2F/R12F.csv  \n",
            "  inflating: Database_draft/R2F/R15F.csv  \n",
            "   creating: Database_draft/R2T/\n",
            "  inflating: Database_draft/R2T/R01T.csv  \n",
            "  inflating: Database_draft/R2T/R02T.csv  \n",
            "  inflating: Database_draft/R2T/R03T.csv  \n",
            "  inflating: Database_draft/R2T/R04T.csv  \n",
            "  inflating: Database_draft/R2T/R05T.csv  \n",
            "  inflating: Database_draft/R2T/R06T.csv  \n",
            "  inflating: Database_draft/R2T/R07T.csv  \n",
            "  inflating: Database_draft/R2T/R08T.csv  \n",
            "  inflating: Database_draft/R2T/R09T.csv  \n",
            "  inflating: Database_draft/R2T/R10T.csv  \n",
            "  inflating: Database_draft/R2T/R11T.csv  \n",
            "  inflating: Database_draft/R2T/R12T.csv  \n",
            "  inflating: Database_draft/R2T/R13T.csv  \n",
            "  inflating: Database_draft/R2T/R14T.csv  \n",
            "  inflating: Database_draft/R2T/R15T.csv  \n",
            "   creating: Database_draft/R3F/\n",
            "  inflating: Database_draft/R3F/R01F.csv  \n",
            "  inflating: Database_draft/R3F/R02F.csv  \n",
            "  inflating: Database_draft/R3F/R03F.csv  \n",
            "  inflating: Database_draft/R3F/R04F.csv  \n",
            "  inflating: Database_draft/R3F/R05F.csv  \n",
            "  inflating: Database_draft/R3F/R06F.csv  \n",
            "  inflating: Database_draft/R3F/R07F.csv  \n",
            "  inflating: Database_draft/R3F/R08F.csv  \n",
            "  inflating: Database_draft/R3F/R09F.csv  \n",
            "  inflating: Database_draft/R3F/R10F.csv  \n",
            "  inflating: Database_draft/R3F/R11F.csv  \n",
            "  inflating: Database_draft/R3F/R12F.csv  \n",
            "  inflating: Database_draft/R3F/R13F.csv  \n",
            "  inflating: Database_draft/R3F/R14F.csv  \n",
            "  inflating: Database_draft/R3F/R15F.csv  \n",
            "   creating: Database_draft/R3T/\n",
            "  inflating: Database_draft/R3T/R01T.csv  \n",
            "  inflating: Database_draft/R3T/R02T.csv  \n",
            "  inflating: Database_draft/R3T/R03T.csv  \n",
            "  inflating: Database_draft/R3T/R04T.csv  \n",
            "  inflating: Database_draft/R3T/R05T.csv  \n",
            "  inflating: Database_draft/R3T/R06T.csv  \n",
            "  inflating: Database_draft/R3T/R07T.csv  \n",
            "  inflating: Database_draft/R3T/R08T.csv  \n",
            "  inflating: Database_draft/R3T/R09T.csv  \n",
            "  inflating: Database_draft/R3T/R10T.csv  \n",
            "  inflating: Database_draft/R3T/R11T.csv  \n",
            "  inflating: Database_draft/R3T/R12T.csv  \n",
            "  inflating: Database_draft/R3T/R13T.csv  \n",
            "  inflating: Database_draft/R3T/R14T.csv  \n",
            "  inflating: Database_draft/R3T/R15T.csv  \n",
            "   creating: Database_draft/TRUCHT_BIEG/\n",
            "  inflating: Database_draft/TRUCHT_BIEG/trucht_bieg.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Database_acc_gyr.zip .\n",
        "!unzip Database_acc_gyr.zip "
      ],
      "metadata": {
        "id": "mx-HHiC8qHln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82a73d87-198b-4f8b-fc17-e48138bcf279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Database_acc_gyr.zip\n",
            "   creating: Database_acc_gyr/\n",
            "   creating: Database_acc_gyr/R1F/\n",
            "   creating: Database_acc_gyr/R1F/R01F/\n",
            "  inflating: Database_acc_gyr/R1F/R01F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R01F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1F/R02F/\n",
            "  inflating: Database_acc_gyr/R1F/R02F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R02F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1F/R03F/\n",
            "  inflating: Database_acc_gyr/R1F/R03F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R03F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1F/R04F/\n",
            "  inflating: Database_acc_gyr/R1F/R04F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R04F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1F/R05F/\n",
            "  inflating: Database_acc_gyr/R1F/R05F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R05F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1F/R06F/\n",
            "  inflating: Database_acc_gyr/R1F/R06F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R06F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1F/R07F/\n",
            "  inflating: Database_acc_gyr/R1F/R07F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R07F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1F/R08F/\n",
            "  inflating: Database_acc_gyr/R1F/R08F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R08F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1F/R09F/\n",
            "  inflating: Database_acc_gyr/R1F/R09F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R09F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1F/R10F/\n",
            "  inflating: Database_acc_gyr/R1F/R10F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R10F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1F/R11F/\n",
            "  inflating: Database_acc_gyr/R1F/R11F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R11F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1F/R12F/\n",
            "  inflating: Database_acc_gyr/R1F/R12F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R12F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1F/R13F/\n",
            "  inflating: Database_acc_gyr/R1F/R13F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R13F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1F/R14F/\n",
            "  inflating: Database_acc_gyr/R1F/R14F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R14F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1F/R15F/\n",
            "  inflating: Database_acc_gyr/R1F/R15F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1F/R15F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/KOZIOL/\n",
            "   creating: Database_acc_gyr/KOZIOL/KOZIOL/\n",
            "  inflating: Database_acc_gyr/KOZIOL/KOZIOL/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/KOZIOL/KOZIOL/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/KOZIOL_TRUCHT_BIEG/\n",
            "   creating: Database_acc_gyr/KOZIOL_TRUCHT_BIEG/KOZIOL_TRUCHT_BIEG/\n",
            "  inflating: Database_acc_gyr/KOZIOL_TRUCHT_BIEG/KOZIOL_TRUCHT_BIEG/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/KOZIOL_TRUCHT_BIEG/KOZIOL_TRUCHT_BIEG/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/\n",
            "   creating: Database_acc_gyr/R1T/R01T/\n",
            "  inflating: Database_acc_gyr/R1T/R01T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R01T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/R02T/\n",
            "  inflating: Database_acc_gyr/R1T/R02T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R02T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/R03T/\n",
            "  inflating: Database_acc_gyr/R1T/R03T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R03T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/R04T/\n",
            "  inflating: Database_acc_gyr/R1T/R04T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R04T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/R05T/\n",
            "  inflating: Database_acc_gyr/R1T/R05T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R05T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/R06T/\n",
            "  inflating: Database_acc_gyr/R1T/R06T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R06T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/R07T/\n",
            "  inflating: Database_acc_gyr/R1T/R07T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R07T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/R08T/\n",
            "  inflating: Database_acc_gyr/R1T/R08T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R08T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/R09T/\n",
            "  inflating: Database_acc_gyr/R1T/R09T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R09T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/R10T/\n",
            "  inflating: Database_acc_gyr/R1T/R10T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R10T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/R11T/\n",
            "  inflating: Database_acc_gyr/R1T/R11T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R11T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/R12T/\n",
            "  inflating: Database_acc_gyr/R1T/R12T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R12T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/R13T/\n",
            "  inflating: Database_acc_gyr/R1T/R13T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R13T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/R14T/\n",
            "  inflating: Database_acc_gyr/R1T/R14T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R14T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R1T/R15T/\n",
            "  inflating: Database_acc_gyr/R1T/R15T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R1T/R15T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/\n",
            "   creating: Database_acc_gyr/R2F/R01F/\n",
            "  inflating: Database_acc_gyr/R2F/R01F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R01F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/R02F/\n",
            "  inflating: Database_acc_gyr/R2F/R02F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R02F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/R03F/\n",
            "  inflating: Database_acc_gyr/R2F/R03F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R03F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/R04F/\n",
            "  inflating: Database_acc_gyr/R2F/R04F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R04F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/R05F/\n",
            "  inflating: Database_acc_gyr/R2F/R05F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R05F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/R06F/\n",
            "  inflating: Database_acc_gyr/R2F/R06F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R06F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/R07F/\n",
            "  inflating: Database_acc_gyr/R2F/R07F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R07F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/R08F/\n",
            "  inflating: Database_acc_gyr/R2F/R08F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R08F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/R09F/\n",
            "  inflating: Database_acc_gyr/R2F/R09F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R09F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/R10F/\n",
            "  inflating: Database_acc_gyr/R2F/R10F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R10F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/R11F/\n",
            "  inflating: Database_acc_gyr/R2F/R11F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R11F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/R13F/\n",
            "  inflating: Database_acc_gyr/R2F/R13F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R13F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/R12F/\n",
            "  inflating: Database_acc_gyr/R2F/R12F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R12F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/R14F/\n",
            "  inflating: Database_acc_gyr/R2F/R14F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R14F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2F/R15F/\n",
            "  inflating: Database_acc_gyr/R2F/R15F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2F/R15F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/\n",
            "   creating: Database_acc_gyr/R2T/R01T/\n",
            "  inflating: Database_acc_gyr/R2T/R01T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R01T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/R02T/\n",
            "  inflating: Database_acc_gyr/R2T/R02T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R02T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/R03T/\n",
            "  inflating: Database_acc_gyr/R2T/R03T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R03T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/R04T/\n",
            "  inflating: Database_acc_gyr/R2T/R04T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R04T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/R05T/\n",
            "  inflating: Database_acc_gyr/R2T/R05T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R05T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/R06T/\n",
            "  inflating: Database_acc_gyr/R2T/R06T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R06T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/R07T/\n",
            "  inflating: Database_acc_gyr/R2T/R07T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R07T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/R08T/\n",
            "  inflating: Database_acc_gyr/R2T/R08T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R08T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/R09T/\n",
            "  inflating: Database_acc_gyr/R2T/R09T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R09T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/R10T/\n",
            "  inflating: Database_acc_gyr/R2T/R10T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R10T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/R11T/\n",
            "  inflating: Database_acc_gyr/R2T/R11T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R11T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/R12T/\n",
            "  inflating: Database_acc_gyr/R2T/R12T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R12T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/R13T/\n",
            "  inflating: Database_acc_gyr/R2T/R13T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R13T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/R14T/\n",
            "  inflating: Database_acc_gyr/R2T/R14T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R14T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R2T/R15T/\n",
            "  inflating: Database_acc_gyr/R2T/R15T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R2T/R15T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/\n",
            "   creating: Database_acc_gyr/R3F/R01F/\n",
            "  inflating: Database_acc_gyr/R3F/R01F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R01F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/R02F/\n",
            "  inflating: Database_acc_gyr/R3F/R02F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R02F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/R03F/\n",
            "  inflating: Database_acc_gyr/R3F/R03F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R03F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/R04F/\n",
            "  inflating: Database_acc_gyr/R3F/R04F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R04F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/R05F/\n",
            "  inflating: Database_acc_gyr/R3F/R05F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R05F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/R06F/\n",
            "  inflating: Database_acc_gyr/R3F/R06F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R06F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/R07F/\n",
            "  inflating: Database_acc_gyr/R3F/R07F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R07F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/R08F/\n",
            "  inflating: Database_acc_gyr/R3F/R08F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R08F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/R09F/\n",
            "  inflating: Database_acc_gyr/R3F/R09F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R09F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/R10F/\n",
            "  inflating: Database_acc_gyr/R3F/R10F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R10F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/R11F/\n",
            "  inflating: Database_acc_gyr/R3F/R11F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R11F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/R12F/\n",
            "  inflating: Database_acc_gyr/R3F/R12F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R12F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/R13F/\n",
            "  inflating: Database_acc_gyr/R3F/R13F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R13F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/R14F/\n",
            "  inflating: Database_acc_gyr/R3F/R14F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R14F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3F/R15F/\n",
            "  inflating: Database_acc_gyr/R3F/R15F/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3F/R15F/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/\n",
            "   creating: Database_acc_gyr/R3T/R01T/\n",
            "  inflating: Database_acc_gyr/R3T/R01T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R01T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/R02T/\n",
            "  inflating: Database_acc_gyr/R3T/R02T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R02T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/R03T/\n",
            "  inflating: Database_acc_gyr/R3T/R03T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R03T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/R04T/\n",
            "  inflating: Database_acc_gyr/R3T/R04T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R04T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/R05T/\n",
            "  inflating: Database_acc_gyr/R3T/R05T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R05T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/R06T/\n",
            "  inflating: Database_acc_gyr/R3T/R06T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R06T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/R07T/\n",
            "  inflating: Database_acc_gyr/R3T/R07T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R07T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/R08T/\n",
            "  inflating: Database_acc_gyr/R3T/R08T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R08T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/R09T/\n",
            "  inflating: Database_acc_gyr/R3T/R09T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R09T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/R10T/\n",
            "  inflating: Database_acc_gyr/R3T/R10T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R10T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/R11T/\n",
            "  inflating: Database_acc_gyr/R3T/R11T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R11T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/R12T/\n",
            "  inflating: Database_acc_gyr/R3T/R12T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R12T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/R13T/\n",
            "  inflating: Database_acc_gyr/R3T/R13T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R13T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/R14T/\n",
            "  inflating: Database_acc_gyr/R3T/R14T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R14T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/R3T/R15T/\n",
            "  inflating: Database_acc_gyr/R3T/R15T/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/R3T/R15T/Gyroscope.csv  \n",
            "   creating: Database_acc_gyr/TRUCHT_BIEG/\n",
            "   creating: Database_acc_gyr/TRUCHT_BIEG/TRUCHT_BIEG/\n",
            "  inflating: Database_acc_gyr/TRUCHT_BIEG/TRUCHT_BIEG/Accelerometer.csv  \n",
            "  inflating: Database_acc_gyr/TRUCHT_BIEG/TRUCHT_BIEG/Gyroscope.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accelerometer_algorithm_act(width, warp, value_for_warp, reverse, up_down, value_for_up_down, scaling,value_for_scaling, new_labels_1):\n",
        "  #Data classification\n",
        "  MAIN_DIRPATH = '/content/Database_draft/'\n",
        "\n",
        "  labels = []\n",
        "  signal_ene = []\n",
        "  mean = []\n",
        "  data =[]\n",
        "\n",
        "  \n",
        "  for dir in os.listdir(MAIN_DIRPATH):\n",
        "    if dir == 'KOZIOL':\n",
        "      label = 0\n",
        "    elif dir == 'KOZIOL_TRUCHT_BIEG':\n",
        "      label = 0\n",
        "    elif dir == 'TRUCHT_BIEG':\n",
        "      label = 1\n",
        "    elif dir == 'R1F':\n",
        "      label = 2\n",
        "    elif dir == 'R1T':\n",
        "      label = 3\n",
        "    elif dir == 'R2F':\n",
        "      label = 4\n",
        "    elif dir == 'R2T':\n",
        "      label = 5\n",
        "    elif dir == 'R3F':\n",
        "      label = 6\n",
        "    elif dir == 'R3T':\n",
        "      label = 7\n",
        "    for file in os.listdir((MAIN_DIRPATH)+dir):\n",
        "      df = pd.read_csv(MAIN_DIRPATH+dir+'/'+file)\n",
        "      acc_mag = acceleration_magnitude(df)\n",
        "      if label <= 2:\n",
        "        data, signal_ene, mean, labels = get_values_from_movement(acc_mag, data, signal_ene, mean, labels, label, width)\n",
        "        break\n",
        "      else:\n",
        "        data, signal_ene, mean, labels = set_values_for_shotting(acc_mag, data, signal_ene, mean, labels, label, width)\n",
        "        if reverse:\n",
        "          data, signal_ene, mean, labels = data_augmentation_rev(acc_mag, data, signal_ene, mean, labels, label, width)\n",
        "        if warp:\n",
        "          data, signal_ene, mean, labels = data_augmentation_warp(acc_mag, data, signal_ene, mean, labels, label, value_for_warp, width)\n",
        "        if value_for_up_down:\n",
        "          data, signal_ene, mean, labels = data_augmentation_up_down(acc_mag, data, signal_ene, mean, labels, label, value_for_up_down, width)\n",
        "        if scaling:\n",
        "          data, signal_ene, mean, labels = data_augmentation_scaling(acc_mag, data, signal_ene, mean, labels, label, value_for_scaling, width)\n",
        "\n",
        "\n",
        "  df = pd.read_csv('Accelerometer.csv')\n",
        "  df_gyro = pd.read_csv('Gyroscope.csv')\n",
        "  ts = pd.to_datetime(df['time'], unit = 'ns')\n",
        "  ts = ts - ts[0]\n",
        "  mag_t = acceleration_magnitude(df)\n",
        "  indexes = get_indexes(mag_t, new_labels_1, width)\n",
        "  new_labels = set_labels(new_labels_1, indexes)\n",
        "  mag_t = acceleration_magnitude(df)\n",
        "  data, mean, signal_ene, labels = cutting_chart_to_pieces(mag_t, data ,mean, signal_ene, labels, new_labels, width)\n",
        "\n",
        "\n",
        "  df = pd.DataFrame(data)\n",
        "  df[\"signal energy\"] = signal_ene\n",
        "  df[\"mean\"] = mean\n",
        "  df[\"labels\"] = labels\n",
        "\n",
        "\n",
        "  df.info()\n",
        "\n",
        "  columns = df.columns\n",
        "  x_columns = columns[:-1]\n",
        "  y_columns = columns[-1]\n",
        "\n",
        "  # NORMALIZACJA\n",
        "  for column in x_columns:\n",
        "      max_v, min_v = df[column].max(), df[column].min()\n",
        "      values = df[column].tolist()\n",
        "      normalized_values = []\n",
        "      for el in values:\n",
        "          try:\n",
        "              el = float(el)\n",
        "              el_n = (el-min_v)/(max_v-min_v) # Tu byl blad\n",
        "              normalized_values.append(el_n)\n",
        "          except:\n",
        "              print(\"znaleziono daną która nie jest liczbą! Zastąpie ją zerem\")\n",
        "              el_n = 0\n",
        "      df[column] = np.array(normalized_values)\n",
        "      \n",
        "  print(\"PO NORMALIZACJI\")\n",
        "  print(df)\n",
        "\n",
        "\n",
        "  y = df[y_columns]\n",
        "  X = df[x_columns]\n",
        "\n",
        "  \n",
        "  length = 2*len(new_labels_1)\n",
        "  X_train = X[:len(X)-length]\n",
        "  y_train = y[:len(X)-length]\n",
        "  X_test = X[len(X)-length:]\n",
        "  y_test = y[len(y)-length:]\n",
        "    \n",
        "\n",
        "  # DEFINE\n",
        "  gnb = GaussianNB()\n",
        "  clf = svm.SVC()\n",
        "  clf_tree = tree.DecisionTreeClassifier()\n",
        "  clf_forest = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "\n",
        "\n",
        "  # TRAIN CLASSIFIERS\n",
        "  gnb.fit(X_train, y_train)\n",
        "  clf.fit(X_train, y_train)\n",
        "  clf_tree.fit(X_train, y_train)\n",
        "  clf_forest.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "  #PREDICTIONS\n",
        "  y_preds_naive = gnb.predict(X_test)\n",
        "  y_preds_svm = clf.predict(X_test)\n",
        "  y_preds_tree = clf_tree.predict(X_test)\n",
        "  y_preds_forest = clf_forest.predict(X_test)\n",
        "\n",
        "\n",
        "  #ACCURACY\n",
        "  acc_naive_bayes = accuracy_score(y_test, y_preds_naive)\n",
        "  acc_svm = accuracy_score(y_test, y_preds_svm)\n",
        "  acc_tree = accuracy_score(y_test, y_preds_tree)\n",
        "  acc_forest = accuracy_score(y_test, y_preds_forest)\n",
        "\n",
        "  # PRINT RESULTS\n",
        "\n",
        "  print(\"ACCURACY\")\n",
        "  print(f\"Naive bayes: {acc_naive_bayes}\")\n",
        "  print(f\"SVM VECTORS: {acc_svm}\")\n",
        "  print(f\"DECISION TREE: {acc_tree}\")\n",
        "  print(f\"RANDOM FOREST: {acc_forest}\")\n",
        "\n",
        "  confusion_matrix_labels = ['K/KTB','TB','R1F','R1T','R2F','R2T','R3F','R3T']\n",
        "\n",
        "  plot_confusion_matrix(gnb, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_naive_acc_act.png')\n",
        "  plt.show()\n",
        "\n",
        "  plot_confusion_matrix(clf, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_svm_acc_act.png')\n",
        "  plt.show()\n",
        "\n",
        "  plot_confusion_matrix(clf_tree, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_decision_tree_acc_act.png')\n",
        "  plt.show()\n",
        "\n",
        "  plot_confusion_matrix(clf_forest, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_random_tree_acc_act.png')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  MAIN_DIRPATH = '/content/Database_acc_gyr/'\n",
        "\n",
        "  labels1 = []\n",
        "  signal_ene1 = []\n",
        "  mean1 = []\n",
        "  z_mean_gyr = []\n",
        "  y_mean_gyr = []\n",
        "  x_mean_gyr = []\n",
        "  data1 =[]\n",
        "\n",
        "  temp = 0\n",
        "\n",
        "  for dir in os.listdir(MAIN_DIRPATH):\n",
        "    if dir == 'KOZIOL':\n",
        "      label = 0\n",
        "    elif dir == 'KOZIOL_TRUCHT_BIEG':\n",
        "      label = 0\n",
        "    elif dir == 'TRUCHT_BIEG':\n",
        "      label = 1\n",
        "    elif dir == 'R1F':\n",
        "      label = 2\n",
        "    elif dir == 'R1T':\n",
        "      label = 3\n",
        "    elif dir == 'R2F':\n",
        "      label = 4\n",
        "    elif dir == 'R2T':\n",
        "      label = 5\n",
        "    elif dir == 'R3F':\n",
        "      label = 6\n",
        "    elif dir == 'R3T':\n",
        "      label = 7\n",
        "    for dir1 in os.listdir((MAIN_DIRPATH)+dir):\n",
        "      for file in os.listdir(((MAIN_DIRPATH)+dir+'/')+dir1):\n",
        "        if 'Gyro' in (MAIN_DIRPATH+dir+'/'+dir1 +'/'+file):\n",
        "          df_gyr = pd.read_csv(MAIN_DIRPATH+dir+'/'+dir1 +'/'+file)\n",
        "          temp +=1\n",
        "        elif 'Acc' in (MAIN_DIRPATH+dir+'/'+dir1 +'/'+file):\n",
        "          df = pd.read_csv(MAIN_DIRPATH+dir+'/'+dir1 +'/'+file)\n",
        "          acc_mag = acceleration_magnitude(df)\n",
        "          temp +=1\n",
        "        if temp == 2:\n",
        "          if label <= 2:\n",
        "            data1, signal_ene1, mean1, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1 = get_values_from_movement_gyr(acc_mag, data1, signal_ene1, mean1, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1, label, width)\n",
        "            temp = 0\n",
        "            break\n",
        "          else:\n",
        "            data1, signal_ene1, mean1, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1 = set_values_for_shotting_gyr(acc_mag, data1, signal_ene1, mean1, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1, label, width)\n",
        "            if reverse:\n",
        "              data1, signal_ene1, mean1, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1 = data_augmentation_rev_gyr(acc_mag, data1, signal_ene1, mean1, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1, label, width)\n",
        "            if warp:\n",
        "              data1, signal_ene1, mean1, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1 = data_augmentation_warp_gyr(acc_mag, data1, signal_ene1, mean1, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1, label, value_for_warp, width)\n",
        "            if up_down:\n",
        "              data1, signal_ene1, mean1, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1 = data_augmentation_up_down_gyr(acc_mag, data1, signal_ene1, mean1, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1, label, value_for_up_down, width)\n",
        "            if scaling:\n",
        "              data1, signal_ene1, mean1, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1 = data_augmentation_scaling_gyr(acc_mag, data1, signal_ene1, mean1, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1, label, value_for_scaling, width)\n",
        "            temp = 0  \n",
        "\n",
        "  df_3t = pd.read_csv('Accelerometer.csv')\n",
        "  df_gyro = pd.read_csv('Gyroscope.csv')\n",
        "  ts_3t = pd.to_datetime(df_3t['time'], unit = 'ns')\n",
        "  ts_3t = ts_3t - ts_3t[0]\n",
        "  mag_t = acceleration_magnitude(df_3t)\n",
        "  indexes = get_indexes(mag_t, new_labels_1,width)\n",
        "  new_labels = set_labels(new_labels_1, indexes)\n",
        "  mag_t = acceleration_magnitude(df_3t)\n",
        "  data1, mean1, signal_ene1, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1 = cutting_chart_to_pieces_gyr(mag_t, data1 ,mean1, signal_ene1, df_gyro, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1, new_labels, width)\n",
        "\n",
        "\n",
        "  df = pd.DataFrame(data1)\n",
        "  df[\"signal energy\"] = signal_ene1\n",
        "  df[\"mean\"] = mean1\n",
        "  df[\"y axis gyroscope mean\"] = z_mean_gyr\n",
        "  df[\"z axis gyroscope mean\"] = y_mean_gyr\n",
        "  df[\"x axis gyroscope mean\"] = x_mean_gyr\n",
        "  df[\"labels\"] = labels1\n",
        "\n",
        "  columns = df.columns\n",
        "  x_columns = columns[:-1]\n",
        "  y_columns = columns[-1]\n",
        "  \n",
        "  df.info()\n",
        "\n",
        "  # NORMALIZACJA\n",
        "  for column in x_columns:\n",
        "      max_v, min_v = df[column].max(), df[column].min()\n",
        "      values = df[column].tolist()\n",
        "      normalized_values = []\n",
        "      for el in values:\n",
        "          try:\n",
        "              el = float(el)\n",
        "              el_n = (el-min_v)/(max_v-min_v) # Tu byl blad\n",
        "              normalized_values.append(el_n)\n",
        "          except:\n",
        "              print(\"znaleziono daną która nie jest liczbą! Zastąpie ją zerem\")\n",
        "              el_n = 0\n",
        "      df[column] = np.array(normalized_values)\n",
        "      \n",
        "      \n",
        "  print(\"PO NORMALIZACJI\")\n",
        "  print(df)\n",
        "\n",
        "\n",
        "  tmp = 0.3\n",
        "  #split data to test and train datasets\n",
        "  y = df[y_columns]\n",
        "  X = df[x_columns]\n",
        "\n",
        "\n",
        "  X_train = X[:len(X)-len(new_labels)]\n",
        "  y_train = y[:len(X)-len(new_labels)]\n",
        "  X_test = X[len(X)-len(new_labels):]\n",
        "  y_test = y[len(y)-len(new_labels):]\n",
        "\n",
        "  # DEFINE\n",
        "  gnb = GaussianNB()\n",
        "  clf = svm.SVC()\n",
        "  clf_tree = tree.DecisionTreeClassifier()\n",
        "  clf_forest = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "\n",
        "\n",
        "  # TRAIN CLASSIFIERS\n",
        "  gnb.fit(X_train, y_train)\n",
        "  clf.fit(X_train, y_train)\n",
        "  clf_tree.fit(X_train, y_train)\n",
        "  clf_forest.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "  #PREDICTIONS\n",
        "  y_preds_naive = gnb.predict(X_test)\n",
        "  y_preds_svm = clf.predict(X_test)\n",
        "  y_preds_tree = clf_tree.predict(X_test)\n",
        "  y_preds_forest = clf_forest.predict(X_test)\n",
        "\n",
        "\n",
        "  #ACCURACY\n",
        "  acc_naive_bayes_1 = accuracy_score(y_test, y_preds_naive)\n",
        "  acc_svm_1 = accuracy_score(y_test, y_preds_svm)\n",
        "  acc_tree_1 = accuracy_score(y_test, y_preds_tree)\n",
        "  acc_forest_1 = accuracy_score(y_test, y_preds_forest)\n",
        "\n",
        "  # PRINT RESULTS\n",
        "\n",
        "  print(\"ACCURACY\")\n",
        "  print(f\"Naive bayes: {acc_naive_bayes_1}\")\n",
        "  print(f\"SVM VECTORS: {acc_svm_1}\")\n",
        "  print(f\"DECISION TREE: {acc_tree_1}\")\n",
        "  print(f\"RANDOM FOREST: {acc_forest_1}\")\n",
        "  \n",
        "  confusion_matrix_labels = ['K/KTB','TB','R1F','R1T','R2F','R2T','R3F','R3T']\n",
        "\n",
        "  plot_confusion_matrix(gnb, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_naive_gyr_act.png')\n",
        "  plt.show()\n",
        "\n",
        "  plot_confusion_matrix(clf, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_svm_gyr_act.png')\n",
        "  plt.show()\n",
        "\n",
        "  plot_confusion_matrix(clf_tree, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_decision_tree_gyr_act.png')\n",
        "  plt.show()\n",
        "\n",
        "  plot_confusion_matrix(clf_forest, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_random_tree_gyr_act.png')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  Sender_Email = \"hojmich@gmail.com\"\n",
        "  Reciever_Email = \"hojmich@gmail.com\"\n",
        "  \n",
        "  Password = input('Enter your email account password: ')\n",
        "\n",
        "  newMessage = EmailMessage()                         \n",
        "  newMessage['Subject'] = \"Result:\" \n",
        "  newMessage['From'] = Sender_Email                   \n",
        "  newMessage['To'] = Reciever_Email                   \n",
        "  newMessage.set_content('The accuracy of the obtained results is as follows:\\n'\n",
        "  + '====Acccelerometer====                 ======Gyroscope and Accelerometer=====\\n'\n",
        "  + '=====ACCURACY=====                  ============ACCURACY============\\n'\n",
        "  + f\"Naive bayes: {round(acc_naive_bayes,2)}                              Naive bayes: {round(acc_naive_bayes_1,2)}\\n\"\n",
        "  + f\"SVM vectors: {round(acc_svm,2)}                              SVM vectors: {round(acc_svm_1,2)}\\n\"\n",
        "  + f\"Decision tree: {round(acc_tree,2)}                              Decision tree: {round(acc_tree_1,2)}\\n\"\n",
        "  + f\"Random forest: {round(acc_forest,2)}                          Random forest: {round(acc_forest_1,2)}\\n\"\n",
        "  + \"==============================================================\\n\"\n",
        "  + \"K - Dribbling \\nKTB - Dribbling while running \\nTB - trucht lub bieg \\nR1F - 1-point field goals missed \\nR1T - 1-point field goals made \\nR2F - 2-point field goals missed \\nR2T - 2-point field goals made \\nR3F - 3-point field goals missed \\nR3T - 3-point field goals made\")\n",
        "\n",
        "  files = ['confussion_matrix_naive_acc_act.png',  'confussion_matrix_svm_acc_act.png', 'confussion_matrix_random_tree_acc_act.png', 'confussion_matrix_decision_tree_acc_act.png', 'confussion_matrix_naive_gyr_act.png',  'confussion_matrix_svm_gyr_act.png', 'confussion_matrix_random_tree_gyr_act.png', 'confussion_matrix_decision_tree_gyr_act.png']\n",
        "\n",
        "  for file in files:\n",
        "    with open(file, 'rb') as f:\n",
        "      image_data = f.read()\n",
        "      image_type = imghdr.what(f.name)\n",
        "      image_name = f.name\n",
        "    newMessage.add_attachment(image_data, maintype = 'image', subtype = image_type, filename = image_name)\n",
        "\n",
        "  with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:\n",
        "      \n",
        "      smtp.login(Sender_Email, Password)              \n",
        "      smtp.send_message(newMessage)"
      ],
      "metadata": {
        "id": "NrcGJDUHiZer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accelerometer_algorithm(width, warp, value_for_warp, reverse, up_down, value_for_up_down, scaling, value_for_scaling):\n",
        "  #Data classification\n",
        "  MAIN_DIRPATH = '/content/Database_draft/'\n",
        "\n",
        "  labels = []\n",
        "  signal_ene = []\n",
        "  mean = []\n",
        "  data =[]\n",
        "\n",
        "  \n",
        "  for dir in os.listdir(MAIN_DIRPATH):\n",
        "    if dir == 'KOZIOL':\n",
        "      label = 0\n",
        "    elif dir == 'KOZIOL_TRUCHT_BIEG':\n",
        "      label = 0\n",
        "    elif dir == 'TRUCHT_BIEG':\n",
        "      label = 1\n",
        "    elif dir == 'R1F':\n",
        "      label = 2\n",
        "    elif dir == 'R1T':\n",
        "      label = 3\n",
        "    elif dir == 'R2F':\n",
        "      label = 4\n",
        "    elif dir == 'R2T':\n",
        "      label = 5\n",
        "    elif dir == 'R3F':\n",
        "      label = 6\n",
        "    elif dir == 'R3T':\n",
        "      label = 7\n",
        "    for file in os.listdir((MAIN_DIRPATH)+dir):\n",
        "      df = pd.read_csv(MAIN_DIRPATH+dir+'/'+file)\n",
        "      acc_mag = acceleration_magnitude(df)\n",
        "      if label <= 1:\n",
        "        data, signal_ene, mean, labels = get_values_from_movement(acc_mag, data, signal_ene, mean, labels, label, width)\n",
        "        break\n",
        "      else:\n",
        "        data, signal_ene, mean, labels = set_values_for_shotting(acc_mag, data, signal_ene, mean, labels, label, width)\n",
        "        if reverse:\n",
        "          data, signal_ene, mean, labels = data_augmentation_rev(acc_mag, data, signal_ene, mean, labels, label, width)\n",
        "        if warp:\n",
        "          data, signal_ene, mean, labels = data_augmentation_warp(acc_mag, data, signal_ene, mean, labels, label, value_for_warp, width)\n",
        "        if value_for_up_down:\n",
        "          data, signal_ene, mean, labels = data_augmentation_up_down(acc_mag, data, signal_ene, mean, labels, label, value_for_up_down, width)\n",
        "        if scaling:\n",
        "          data, signal_ene, mean, labels = data_augmentation_scaling(acc_mag, data, signal_ene, mean, labels, label, value_for_scaling, width)\n",
        "\n",
        "\n",
        "  df = pd.DataFrame(data)\n",
        "  df[\"signal energy\"] = signal_ene\n",
        "  df[\"mean\"] = mean\n",
        "  df[\"labels\"] = labels\n",
        "\n",
        "\n",
        "  columns = df.columns\n",
        "  x_columns = columns[:-1]\n",
        "  y_columns = columns[-1]\n",
        "\n",
        "  df.info()\n",
        "  print(df)\n",
        "\n",
        "  # NORMALIZACJA\n",
        "  for column in x_columns:\n",
        "      max_v, min_v = df[column].max(), df[column].min()\n",
        "      values = df[column].tolist()\n",
        "      normalized_values = []\n",
        "      for el in values:\n",
        "          try:\n",
        "              el = float(el)\n",
        "              el_n = (el-min_v)/(max_v-min_v) # Tu byl blad\n",
        "              normalized_values.append(el_n)\n",
        "          except:\n",
        "              print(\"znaleziono daną która nie jest liczbą! Zastąpie ją zerem\")\n",
        "              el_n = 0\n",
        "      df[column] = np.array(normalized_values)\n",
        "      \n",
        "  print(\"PO NORMALIZACJI\")\n",
        "\n",
        "  tmp = 0.3\n",
        "  y = df[y_columns]\n",
        "  X = df[x_columns]\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tmp, random_state=42)\n",
        "    \n",
        "\n",
        "  # DEFINE\n",
        "  gnb = GaussianNB()\n",
        "  clf = svm.SVC()\n",
        "  clf_tree = tree.DecisionTreeClassifier()\n",
        "  clf_forest = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "\n",
        "\n",
        "  # TRAIN CLASSIFIERS\n",
        "  gnb.fit(X_train, y_train)\n",
        "  clf.fit(X_train, y_train)\n",
        "  clf_tree.fit(X_train, y_train)\n",
        "  clf_forest.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "  #PREDICTIONS\n",
        "  y_preds_naive = gnb.predict(X_test)\n",
        "  y_preds_svm = clf.predict(X_test)\n",
        "  y_preds_tree = clf_tree.predict(X_test)\n",
        "  y_preds_forest = clf_forest.predict(X_test)\n",
        "\n",
        "\n",
        "  #ACCURACY\n",
        "  acc_naive_bayes = accuracy_score(y_test, y_preds_naive)\n",
        "  acc_svm = accuracy_score(y_test, y_preds_svm)\n",
        "  acc_tree = accuracy_score(y_test, y_preds_tree)\n",
        "  acc_forest = accuracy_score(y_test, y_preds_forest)\n",
        "\n",
        "  # PRINT RESULTS\n",
        "\n",
        "  print(\"ACCURACY\")\n",
        "  print(f\"Naive bayes: {acc_naive_bayes}\")\n",
        "  print(f\"SVM VECTORS: {acc_svm}\")\n",
        "  print(f\"DECISION TREE: {acc_tree}\")\n",
        "  print(f\"RANDOM FOREST: {acc_forest}\")\n",
        "\n",
        "\n",
        "  confusion_matrix_labels = ['K/KTB','TB','R1F','R1T','R2F','R2T','R3F','R3T']\n",
        "\n",
        "  plot_confusion_matrix(gnb, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_naive_acc.png')\n",
        "  plt.show()\n",
        "\n",
        "  plot_confusion_matrix(clf, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_svm_acc.png')\n",
        "  plt.show()\n",
        "\n",
        "  plot_confusion_matrix(clf_tree, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_decision_tree_acc.png')\n",
        "  plt.show()\n",
        "\n",
        "  plot_confusion_matrix(clf_forest, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_random_tree_acc.png')\n",
        "  plt.show()\n",
        "\n",
        "  print(\"gyroscope\")\n",
        "\n",
        "  MAIN_DIRPATH = '/content/Database_acc_gyr/'\n",
        "\n",
        "  labels1 = []\n",
        "  signal_ene1 = []\n",
        "  mean1 = []\n",
        "  z_mean_gyr = []\n",
        "  y_mean_gyr = []\n",
        "  x_mean_gyr = []\n",
        "  data1 =[]\n",
        "\n",
        "  temp = 0\n",
        "\n",
        "\n",
        "  for dir in os.listdir(MAIN_DIRPATH):\n",
        "    if dir == 'KOZIOL':\n",
        "      label = 0\n",
        "    elif dir == 'KOZIOL_TRUCHT_BIEG':\n",
        "      label = 0\n",
        "    elif dir == 'TRUCHT_BIEG':\n",
        "      label = 1\n",
        "    elif dir == 'R1F':\n",
        "      label = 2\n",
        "    elif dir == 'R1T':\n",
        "      label = 3\n",
        "    elif dir == 'R2F':\n",
        "      label = 4\n",
        "    elif dir == 'R2T':\n",
        "      label = 5\n",
        "    elif dir == 'R3F':\n",
        "      label = 6\n",
        "    elif dir == 'R3T':\n",
        "      label = 7\n",
        "    for dir1 in os.listdir((MAIN_DIRPATH)+dir):\n",
        "      for file in os.listdir(((MAIN_DIRPATH)+dir+'/')+dir1):\n",
        "        if 'Gyro' in (MAIN_DIRPATH+dir+'/'+dir1 +'/'+file):\n",
        "          df_gyr = pd.read_csv(MAIN_DIRPATH+dir+'/'+dir1 +'/'+file)\n",
        "          temp +=1\n",
        "        elif 'Acc' in (MAIN_DIRPATH+dir+'/'+dir1 +'/'+file):\n",
        "          df = pd.read_csv(MAIN_DIRPATH+dir+'/'+dir1 +'/'+file)\n",
        "          acc_mag = acceleration_magnitude(df)\n",
        "          temp +=1\n",
        "        if temp == 2:\n",
        "          if label <= 1:\n",
        "            data1, signal_ene1, mean1, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1 = get_values_from_movement_gyr(acc_mag, data1, signal_ene1, mean1, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1, label, width)\n",
        "            temp = 0\n",
        "            break\n",
        "          else:\n",
        "            data1, signal_ene1, mean1, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1 = set_values_for_shotting_gyr(acc_mag, data1, signal_ene1, mean1, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1, label, width)\n",
        "            if reverse:\n",
        "              data1, signal_ene1, mean1, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1 = data_augmentation_rev_gyr(acc_mag, data1, signal_ene1, mean1, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1, label, width)\n",
        "            if warp:\n",
        "              data1, signal_ene1, mean1, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1 = data_augmentation_warp_gyr(acc_mag, data1, signal_ene1, mean1, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1, label, value_for_warp, width)\n",
        "            if up_down:\n",
        "              data1, signal_ene1, mean1, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1 = data_augmentation_up_down_gyr(acc_mag, data1, signal_ene1, mean1, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1, label, value_for_up_down, width)\n",
        "            if scaling:\n",
        "              data1, signal_ene1, mean1, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1 = data_augmentation_scaling_gyr(acc_mag, data1, signal_ene1, mean1, df_gyr, z_mean_gyr, y_mean_gyr, x_mean_gyr, labels1, label, value_for_scaling, width)\n",
        "            temp = 0  \n",
        "\n",
        "\n",
        "  df_1 = pd.DataFrame(data1)\n",
        "  df_1[\"signal energy\"] = signal_ene1\n",
        "  df_1[\"mean\"] = mean1\n",
        "  df_1[\"y axis gyr mean\"] = z_mean_gyr\n",
        "  df_1[\"z axis gyr mean\"] = y_mean_gyr\n",
        "  df_1[\"x axis gyr mean\"] = x_mean_gyr\n",
        "  df_1[\"labels\"] = labels1\n",
        "\n",
        "\n",
        "  columns = df_1.columns\n",
        "  x_columns = columns[:-1]\n",
        "  y_columns = columns[-1]\n",
        "\n",
        "  df_1.info()\n",
        "  print(df_1)\n",
        "  \n",
        "  # NORMALIZACJA\n",
        "  for column in x_columns:\n",
        "      max_v, min_v = df_1[column].max(), df_1[column].min()\n",
        "      values = df_1[column].tolist()\n",
        "      normalized_values = []\n",
        "      for el in values:\n",
        "          try:\n",
        "              el = float(el)\n",
        "              el_n = (el-min_v)/(max_v-min_v) # Tu byl blad\n",
        "              normalized_values.append(el_n)\n",
        "          except:\n",
        "              print(\"znaleziono daną która nie jest liczbą! Zastąpie ją zerem\")\n",
        "              el_n = 0\n",
        "      df_1[column] = np.array(normalized_values)\n",
        "      \n",
        "      \n",
        "  print(\"PO NORMALIZACJI\")\n",
        "\n",
        "\n",
        "  tmp = 0.3\n",
        "  #split data to test and train datasets\n",
        "  y = df_1[y_columns]\n",
        "  X = df_1[x_columns]\n",
        "\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tmp, random_state=42)\n",
        "\n",
        "  # DEFINE\n",
        "  gnb = GaussianNB()\n",
        "  clf = svm.SVC()\n",
        "  clf_tree = tree.DecisionTreeClassifier()\n",
        "  clf_forest = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "\n",
        "\n",
        "  # TRAIN CLASSIFIERS\n",
        "  gnb.fit(X_train, y_train)\n",
        "  clf.fit(X_train, y_train)\n",
        "  clf_tree.fit(X_train, y_train)\n",
        "  clf_forest.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "  #PREDICTIONS\n",
        "  y_preds_naive = gnb.predict(X_test)\n",
        "  y_preds_svm = clf.predict(X_test)\n",
        "  y_preds_tree = clf_tree.predict(X_test)\n",
        "  y_preds_forest = clf_forest.predict(X_test)\n",
        "\n",
        "\n",
        "  #ACCURACY\n",
        "  acc_naive_bayes_1 = accuracy_score(y_test, y_preds_naive)\n",
        "  acc_svm_1 = accuracy_score(y_test, y_preds_svm)\n",
        "  acc_tree_1 = accuracy_score(y_test, y_preds_tree)\n",
        "  acc_forest_1 = accuracy_score(y_test, y_preds_forest)\n",
        "\n",
        "  # PRINT RESULTS\n",
        "\n",
        "  print(\"ACCURACY\")\n",
        "  print(f\"Naive bayes: {acc_naive_bayes_1}\")\n",
        "  print(f\"SVM VECTORS: {acc_svm_1}\")\n",
        "  print(f\"DECISION TREE: {acc_tree_1}\")\n",
        "  print(f\"RANDOM FOREST: {acc_forest_1}\")\n",
        "\n",
        "\n",
        "  confusion_matrix_labels = ['K/KTB','TB','R1F','R1T','R2F','R2T','R3F','R3T']\n",
        "\n",
        "  plot_confusion_matrix(gnb, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_naive_acc_gyr.png')\n",
        "  plt.show()\n",
        "\n",
        "  plot_confusion_matrix(clf, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_svm_acc_gyr.png')\n",
        "  plt.show()\n",
        "\n",
        "  plot_confusion_matrix(clf_tree, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_decision_tree_acc_gyr.png')\n",
        "  plt.show()\n",
        "\n",
        "  plot_confusion_matrix(clf_forest, X_test, y_test, display_labels = confusion_matrix_labels, xticks_rotation='vertical')\n",
        "  plt.savefig('confussion_matrix_random_tree_acc_gyr.png')\n",
        "  plt.show()\n",
        "\n",
        "  Sender_Email = \"hojmich@gmail.com\"\n",
        "  Reciever_Email = \"hojmich@gmail.com\"\n",
        "  \n",
        "  Password = input('Enter your email account password: ')\n",
        "\n",
        "  newMessage = EmailMessage()                         \n",
        "  newMessage['Subject'] = \"Result:\" \n",
        "  newMessage['From'] = Sender_Email                   \n",
        "  newMessage['To'] = Reciever_Email                   \n",
        "  newMessage.set_content('The accuracy of the obtained results is as follows:\\n'\n",
        "  + '====Acccelerometer====                  =====Gyroscope and Accelerometer=====\\n'\n",
        "  + '=====ACCURACY=====                 =============ACCURACY=============\\n'\n",
        "  + f\"Naive bayes: {round(acc_naive_bayes,2)}                              Naive bayes: {round(acc_naive_bayes_1,2)}\\n\"\n",
        "  + f\"SVM vectors: {round(acc_svm,2)}                               SVM vectors: {round(acc_svm_1,2)}\\n\"\n",
        "  + f\"Decision tree: {round(acc_tree,2)}                               Decision tree: {round(acc_tree_1,2)}\\n\"\n",
        "  + f\"Random forest: {round(acc_forest,2)}                           Random forest: {round(acc_forest_1,2)}\\n\"\n",
        "  + \"==============================================================\\n\"\n",
        "  + \"K - Dribbling \\nKTB - Dribbling while running \\nTB - trucht lub bieg \\nR1F - 1-point field goals missed \\nR1T - 1-point field goals made \\nR2F - 2-point field goals missed \\nR2T - 2-point field goals made \\nR3F - 3-point field goals missed \\nR3T - 3-point field goals made\")\n",
        "\n",
        "  files = ['confussion_matrix_naive_acc.png',  'confussion_matrix_svm_acc.png', 'confussion_matrix_random_tree_acc.png', 'confussion_matrix_decision_tree_acc.png', 'confussion_matrix_naive_acc_gyr.png',  'confussion_matrix_svm_acc_gyr.png', 'confussion_matrix_random_tree_acc_gyr.png', 'confussion_matrix_decision_tree_acc_gyr.png']\n",
        "\n",
        "  for file in files:\n",
        "    with open(file, 'rb') as f:\n",
        "      image_data = f.read()\n",
        "      image_type = imghdr.what(f.name)\n",
        "      image_name = f.name\n",
        "    newMessage.add_attachment(image_data, maintype = 'image', subtype = image_type, filename = image_name)\n",
        "\n",
        "  with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:\n",
        "      \n",
        "      smtp.login(Sender_Email, Password)              \n",
        "      smtp.send_message(newMessage)"
      ],
      "metadata": {
        "id": "bi_j_Psk72zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accelerometer_algorithm(30,0,0,0,0,0,0,0)"
      ],
      "metadata": {
        "id": "mH0KjIQfwQ2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accelerometer_algorithm_act(40,0,0,0,0,0,0,0,[3,5,7,2,4,6,3,5,7,2,4,6])"
      ],
      "metadata": {
        "id": "oT2rz1f2ISgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rH6iiKmQd5X8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}